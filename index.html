<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web AR Image Analyzer</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@2.1.0/dist/mobilenet.min.js"></script>
    <style>
        body { margin: 0; background: #000; color: #fff; text-align: center; }
        #videoElement { 
            width: 100vw; 
            height: 100vh; 
            object-fit: cover; /* AR feel: cover the whole screen */
            /* Removed 'transform: scaleX(-1)' for external camera (back camera) unless a front camera is used */
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1;
        }
        #results {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 10;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px 20px;
            border-radius: 10px;
            font-family: Arial, sans-serif;
            font-size: 1.2em;
            text-align: left;
            min-width: 300px;
        }
    </style>
</head>
<body>

    <video id="videoElement" autoplay muted playsinline></video>

    <div id="results">
        Initializing...
    </div>

    <script>
        // --- 2. Camera Access Setup ---
        const video = document.getElementById('videoElement');
        const resultsDiv = document.getElementById('results');
        const FRAME_RATE = 5; // Analyze at 5 frames per second for better performance

        // Request access to the camera with failover
        async function setupCamera() {
            resultsDiv.innerHTML = 'Requesting Camera Access...';
            try {
                // Try 'environment' (back camera) first
                let stream = await navigator.mediaDevices.getUserMedia({ 
                    'video': { facingMode: 'environment' }, 
                    'audio': false 
                });
                
                video.srcObject = stream;
                video.play();
                resultsDiv.innerHTML = 'Back Camera Active.';

            } catch (error) {
                // If 'environment' fails, try the default camera (often front-facing)
                try {
                    resultsDiv.innerHTML = 'Back camera unavailable. Trying default...';
                    let stream = await navigator.mediaDevices.getUserMedia({ 
                        'video': true, 
                        'audio': false 
                    });
                    
                    video.srcObject = stream;
                    video.play();
                    
                    // Add mirror effect if we suspect it's the front camera
                    video.style.transform = 'scaleX(-1)'; 
                    resultsDiv.innerHTML = 'Default Camera Active (Mirrored).';

                } catch (finalError) {
                    // Both camera attempts failed
                    resultsDiv.innerHTML = '❌ Error: Camera access failed. <br>Ensure a camera is available and permissions are granted.';
                    console.error('Final Camera Error:', finalError);
                    return false; // Indicate failure
                }
            }

            // Wait for the video to actually load data and start playing
            return new Promise((resolve) => {
                video.onloadeddata = () => {
                     resolve(true); // Indicate success
                };
            });
        }

        // --- 3. ML Model Loading and Prediction ---
        let model;

        async function loadModel() {
            resultsDiv.innerHTML = 'Loading MobileNet Model...';
            try {
                // Load a lighter model for mobile performance
                model = await mobilenet.load({
                    version: 1, 
                    alpha: 0.25
                });
                resultsDiv.innerHTML = 'Model Loaded! Analyzing...';
                return true;
            } catch (e) {
                resultsDiv.innerHTML = '❌ Error: Failed to load MobileNet model.';
                console.error('Model Load Error:', e);
                return false;
            }
        }

        async function classifyVideo() {
            if (!model || video.paused || video.ended) return;

            // Make a prediction on the current video frame
            const predictions = await model.classify(video);

            // Display results
            let output = '<strong>What I See:</strong><br>';
            
            predictions.slice(0, 3).forEach(prediction => {
                const probability = (prediction.probability * 100).toFixed(2);
                const className = prediction.className.split(',')[0].trim(); // Use only the primary label
                output += `${className} (${probability}%)<br>`;
            });

            resultsDiv.innerHTML = output;

            // Use setTimeout to control the FPS for performance
            setTimeout(classifyVideo, 1000 / FRAME_RATE);
        }

        // --- 4. Main Execution ---
        async function main() {
            const cameraReady = await setupCamera();
            if (!cameraReady) return;

            const modelReady = await loadModel();
            if (!modelReady) return;

            // Start the continuous prediction loop
            classifyVideo();
        }

        main();
    </script>
</body>
</html>
