<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web AR Image Analyzer</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@2.1.0/dist/mobilenet.min.js"></script>
    <style>
        body { margin: 0; background: #000; color: #fff; text-align: center; }
        #videoElement { 
            width: 100vw; 
            height: 100vh; 
            object-fit: cover; /* AR feel: cover the whole screen */
            transform: scaleX(-1); /* Mirror the video for a selfie/AR feel */
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1;
        }
        #results {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 10;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px 20px;
            border-radius: 10px;
            font-family: Arial, sans-serif;
            font-size: 1.2em;
            text-align: left;
            min-width: 300px;
        }
    </style>
</head>
<body>

    <video id="videoElement" autoplay muted playsinline></video>

    <div id="results">
        Loading Model...
    </div>

    <script>
        // --- 2. Camera Access Setup ---
        const video = document.getElementById('videoElement');
        const resultsDiv = document.getElementById('results');
        
        // Request access to the camera
        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    'video': { facingMode: 'environment' }, // Prefer back camera
                    'audio': false 
                });
                video.srcObject = stream;
                // Wait for the video to load before starting analysis
                return new Promise((resolve) => {
                    video.onloadeddata = () => {
                        resolve(video);
                    };
                });
            } catch (error) {
                resultsDiv.innerHTML = 'Error: Camera access denied or not supported. Please ensure you are on HTTPS.';
                console.error(error);
            }
        }

        // --- 3. ML Model Loading and Prediction ---
        let model;

        async function loadModelAndStartAnalysis() {
            resultsDiv.innerHTML = 'Loading MobileNet Model...';
            // Load the MobileNet model
            model = await mobilenet.load();
            resultsDiv.innerHTML = 'Model Loaded! Analyzing...';
            
            // Start the continuous prediction loop
            classifyVideo();
        }

        async function classifyVideo() {
            if (!model) return;

            // Make a prediction on the current video frame
            const predictions = await model.classify(video);

            // Clear previous results and display new ones
            let output = '<strong>What I See:</strong><br>';
            
            // Display the top 3 predictions
            predictions.slice(0, 3).forEach(prediction => {
                // Format the probability as a percentage
                const probability = (prediction.probability * 100).toFixed(2);
                output += `${prediction.className} (${probability}%)<br>`;
            });

            resultsDiv.innerHTML = output;

            // Request the browser to call classifyVideo again on the next animation frame
            // This creates a smooth, continuous analysis loop (the 'AR' part)
            requestAnimationFrame(classifyVideo);
        }

        // --- 4. Main Execution ---
        async function main() {
            await setupCamera();
            // Start loading the model only after the video is ready
            video.addEventListener('play', loadModelAndStartAnalysis);
        }

        main();
    </script>
</body>
</html>
